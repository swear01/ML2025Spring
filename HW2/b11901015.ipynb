{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMksFjyDhCyG"
      },
      "source": [
        "# Machine Learning Course 2025 HW2\n",
        "The code scripts are from [aideml](https://github.com/WecoAI/aideml) project on github with some modifications.\n",
        "\n",
        "AIDE: AI-Driven Exploration in the Space of Code\n",
        "\n",
        "https://arxiv.org/pdf/2502.13138"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubu98XRV3kCe"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZmTzUexsG7e",
        "outputId": "66410e91-8abd-40c6-da26-6fe22fb8f9b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n$env:CMAKE_ARGS = \"-DGGML_CUDA=ON\"\\npip install . --verbose --force-reinstall --no-cache-dir\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to install locally built llama-cpp-python (20min+)\n",
        "\"\"\"\n",
        "$env:CMAKE_ARGS = \"-DGGML_CUDA=ON\"\n",
        "pip install . --verbose --force-reinstall --no-cache-dir\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXR6hQIa5sML",
        "outputId": "a345ad11-1e72-4b1e-dc6a-8e6fd043eaf3"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "\n",
        "# !gdown 1Ah5uV6cu3Bnz6WfkUuxEZCLqj5k1lbpd\n",
        "\n",
        "# Choose a workable link\n",
        "# !gdown --id 1XtF9-hGw2tKe4WvUMW5YE6lj6p1QcWIc\n",
        "# !gdown --id 1diswE_9XoT-uII23ucRppau1ErEQkY2y\n",
        "# !gdown --id 1BAVMzLZqEgtG8rwog7ttC7xKPw5QTngn\n",
        "# !gdown --id 1PAI4_3kRWwIPQMscMdGt9HLqZZy1vWSD\n",
        "\n",
        "# !unzip /content/ML2025Spring-hw2-public.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZozqjSIgfAuJ",
        "outputId": "1c1572b3-c022-4548-be0b-7b7a18689672"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_context: n_ctx_per_seq (10000) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    from llama_cpp import Llama\n",
        "\n",
        "    # Load the model onto GPU\n",
        "    myModel = Llama(\n",
        "        # Before changing LLM, restart the session!\n",
        "        \"../google_gemma-3-12b-it-IQ4_XS.gguf\",\n",
        "        #\"../Qwen2.5-14B-Instruct-IQ4_XS.gguf\",\n",
        "        verbose=False,\n",
        "        n_gpu_layers=-1,\n",
        "        n_ctx=10000,    # This argument is how many tokens the model can take. The longer the better, but it will consume more memory.\n",
        "    )\n",
        "    def generate_response(_model: Llama, _messages: str) -> str:\n",
        "        '''\n",
        "        This function will inference the model with given messages.\n",
        "        '''\n",
        "        _output = _model.create_chat_completion(\n",
        "            _messages,\n",
        "            stop=[\"<|eot_id|>\", \"<|end_of_text|>\"],\n",
        "            max_tokens=4096,    # This argument is how many tokens the model can generate.\n",
        "            temperature=0.1,    # Somewhat higher temperature will create better results.\n",
        "        )[\"choices\"][0][\"message\"][\"content\"]\n",
        "        return _output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgRw-Rt740fF"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf1drXU_MvAP"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cBIdD6RrMuY5"
      },
      "outputs": [],
      "source": [
        "# Define a function to save the best solution and other good solutions to files.\n",
        "def save_run(cfg, journal):\n",
        "    # Retrieve and save the best found solution.\n",
        "    best_node = journal.get_best_node(only_good=False)  # Get the best node.\n",
        "    with open(\"best_solution.py\", \"w\") as f:\n",
        "        f.write(best_node.code)\n",
        "\n",
        "    good_nodes = journal.get_good_nodes()  # Retrieve all good solution nodes.\n",
        "    for i, node in enumerate(good_nodes):\n",
        "        filename = f\"good_solution_{i}.py\"\n",
        "        with open(filename, \"w\") as f:\n",
        "            f.write(node.code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJIf1li3ifQN"
      },
      "source": [
        "### Interpreter (DO NOT MODIFY THIS CELL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e6T1m16_7MCw"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    DO NOT MODIFY THIS CELL\n",
        "\n",
        "    Python interpreter for executing code snippets and capturing their output.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    import logging\n",
        "    import os\n",
        "    import queue\n",
        "    import signal\n",
        "    import sys\n",
        "    import time\n",
        "    import traceback\n",
        "    import zipfile\n",
        "    from pathlib import Path\n",
        "    from shutil import rmtree\n",
        "    import shutil\n",
        "    from multiprocessing import Process, Queue\n",
        "    from typing import Hashable, cast\n",
        "\n",
        "    import humanize\n",
        "    import rich\n",
        "    import shutup\n",
        "    from rich.logging import RichHandler\n",
        "    from rich.syntax import Syntax\n",
        "    from dataclasses import dataclass\n",
        "    from dataclasses_json import DataClassJsonMixin\n",
        "\n",
        "\n",
        "    @dataclass\n",
        "    class ExecutionResult(DataClassJsonMixin):\n",
        "        \"\"\"\n",
        "        Result of executing a code snippet in the interpreter.\n",
        "        Contains the output, execution time, and exception information.\n",
        "        \"\"\"\n",
        "        term_out: list[str]\n",
        "        exec_time: float\n",
        "        exc_type: str | None\n",
        "        exc_info: dict | None = None\n",
        "        exc_stack: list[tuple] | None = None\n",
        "\n",
        "    def exception_summary(e, exec_file_name):\n",
        "        \"\"\"Generates a string that summarizes an exception and its stack trace\"\"\"\n",
        "        tb_lines = traceback.format_exception(e)\n",
        "        # Combine the traceback lines into a single string, skipping lines that contain \"importlib\".\n",
        "        tb_str = \"\".join(\n",
        "            [\n",
        "                line\n",
        "                for line in tb_lines\n",
        "                # if \"importlib\" not in line  # Filter out unwanted traceback lines.\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        exc_info = {}\n",
        "        if hasattr(e, \"args\"):\n",
        "            exc_info[\"args\"] = [str(i) for i in e.args]  # Store the exception arguments as strings.\n",
        "        for att in [\"name\", \"msg\", \"obj\"]:\n",
        "            if hasattr(e, att):\n",
        "                exc_info[att] = str(getattr(e, att))  # Store additional attributes if available.\n",
        "\n",
        "        tb = traceback.extract_tb(e.__traceback__)  # Extract the traceback information.\n",
        "        # Create a list of tuples for each frame in the traceback.\n",
        "        exc_stack = [(t.filename, t.lineno, t.name, t.line) for t in tb]\n",
        "\n",
        "        return tb_str, e.__class__.__name__, exc_info, exc_stack  # Return the formatted traceback and exception details.\n",
        "\n",
        "    # Define a class that redirects write operations to a multiprocessing queue.\n",
        "    class RedirectQueue:\n",
        "        def __init__(self, queue, timeout=5):\n",
        "            self.queue = queue  # Store the provided queue.\n",
        "            self.timeout = timeout  # Set the timeout for queue operations.\n",
        "\n",
        "        def write(self, msg):\n",
        "            try:\n",
        "                self.queue.put(msg, timeout=self.timeout)  # Attempt to put the message into the queue.\n",
        "            except queue.Full:\n",
        "                print.warning(\"Queue write timed out\")  # Warn if the queue is full and the write times out.\n",
        "\n",
        "        def flush(self):\n",
        "            pass  # No operation is needed for flushing in this context.\n",
        "\n",
        "    # Define the Interpreter class that simulates a standalone Python REPL.\n",
        "    class Interpreter:\n",
        "        def __init__(\n",
        "            self,\n",
        "            timeout: int = 3600,  # Default timeout of 3600 seconds.\n",
        "            agent_file_name: str = \"runfile.py\",  # Default file name for writing the agent's code.\n",
        "        ):\n",
        "            \"\"\"\n",
        "            Simulates a standalone Python REPL with an execution time limit.\n",
        "\n",
        "            Args:\n",
        "                timeout (int, optional): Timeout for each code execution step. Defaults to 3600.\n",
        "                agent_file_name (str, optional): The name for the agent's code file. Defaults to \"runfile.py\".\n",
        "            \"\"\"\n",
        "            self.timeout = timeout  # Save the timeout value.\n",
        "            self.agent_file_name = agent_file_name  # Save the agent file name.\n",
        "            self.process: Process = None  # Initialize the process attribute (will hold the child process).\n",
        "\n",
        "        def child_proc_setup(self, result_outq: Queue) -> None:\n",
        "            # Import shutup to suppress warnings in the child process.\n",
        "            import shutup\n",
        "\n",
        "            shutup.mute_warnings()  # Mute all warnings before further execution.\n",
        "\n",
        "            # Redirect both stdout and stderr to the provided result queue.\n",
        "            # trunk-ignore(mypy/assignment)\n",
        "            sys.stdout = sys.stderr = RedirectQueue(result_outq)\n",
        "\n",
        "        def _run_session(\n",
        "            self, code_inq: Queue, result_outq: Queue, event_outq: Queue\n",
        "        ) -> None:\n",
        "            self.child_proc_setup(result_outq)  # Set up the child process for capturing output.\n",
        "\n",
        "            global_scope: dict = {}  # Create an empty dictionary to serve as the global scope.\n",
        "            while True:  # Continuously wait for new code to execute.\n",
        "                code = code_inq.get()  # Retrieve code from the code input queue.\n",
        "                with open(self.agent_file_name, \"w\") as f:  # Open the agent file for writing.\n",
        "                    f.write(code)  # Write the received code into the file.\n",
        "\n",
        "                event_outq.put((\"state:ready\",))  # Signal that the interpreter is ready to execute the code.\n",
        "                try:\n",
        "                    # Compile and execute the code within the global scope.\n",
        "                    exec(compile(code, self.agent_file_name, \"exec\"), global_scope)\n",
        "                except BaseException as e:\n",
        "                    # If an exception occurs, generate a summary of the exception.\n",
        "                    tb_str, e_cls_name, exc_info, exc_stack = exception_summary(\n",
        "                        e,\n",
        "                        self.agent_file_name,\n",
        "                    )\n",
        "                    result_outq.put(tb_str)  # Put the traceback string into the result queue.\n",
        "                    if e_cls_name == \"KeyboardInterrupt\":\n",
        "                        e_cls_name = \"TimeoutError\"  # Convert a KeyboardInterrupt into a TimeoutError.\n",
        "\n",
        "                    event_outq.put((\"state:finished\", e_cls_name, exc_info, exc_stack))  # Signal that execution finished with an error.\n",
        "                else:\n",
        "                    event_outq.put((\"state:finished\", None, None, None))  # Signal that execution finished successfully.\n",
        "\n",
        "                os.remove(self.agent_file_name)  # Remove the agent file after execution.\n",
        "\n",
        "                result_outq.put(\"<|EOF|>\")  # Put an EOF marker to indicate the end of output.\n",
        "\n",
        "        def create_process(self) -> None:\n",
        "            # Create three queues for communication with the child process:\n",
        "            # - code_inq: for sending code to execute.\n",
        "            # - result_outq: for receiving output from the execution.\n",
        "            # - event_outq: for receiving state events (like ready and finished).\n",
        "            # trunk-ignore(mypy/var-annotated)\n",
        "            self.code_inq, self.result_outq, self.event_outq = Queue(), Queue(), Queue()\n",
        "            self.process = Process(\n",
        "                target=self._run_session,  # Set the target function for the child process.\n",
        "                args=(self.code_inq, self.result_outq, self.event_outq),  # Provide the necessary queues as arguments.\n",
        "            )\n",
        "            self.process.start()  # Start the child process.\n",
        "\n",
        "        def cleanup_session(self):\n",
        "            if self.process is None:  # If there is no process, nothing to clean up.\n",
        "                return\n",
        "            try:\n",
        "                # Attempt to terminate the child process gracefully.\n",
        "                self.process.terminate()  # Request the process to terminate.\n",
        "                self.process.join(timeout=0.5)  # Wait for the process to finish with a 0.5-second timeout.\n",
        "\n",
        "                if self.process.exitcode is None:  # If the process is still running,\n",
        "                    self.process.kill()  # Forcefully kill the process.\n",
        "                    self.process.join(timeout=0.5)  # Wait again for termination.\n",
        "\n",
        "                    if self.process.exitcode is None:  # If the process still hasn't terminated,\n",
        "                        os.kill(self.process.pid, signal.SIGKILL)  # Send a SIGKILL signal.\n",
        "            except Exception as e:\n",
        "                print(f\"Error during process cleanup: {e}\")  # Print an error message if cleanup fails.\n",
        "            finally:\n",
        "                if self.process is not None:  # If the process exists,\n",
        "                    self.process.close()  # Close the process.\n",
        "                    self.process = None  # Reset the process attribute to None.\n",
        "\n",
        "        def run(self, code: str, reset_session=True) -> ExecutionResult:\n",
        "            \"\"\"\n",
        "            Execute the provided Python command in a separate process and return its output.\n",
        "\n",
        "            Parameters:\n",
        "                code (str): Python code to execute.\n",
        "                reset_session (bool, optional): Whether to reset the interpreter session before executing the code. Defaults to True.\n",
        "\n",
        "            Returns:\n",
        "                ExecutionResult: Object containing the output and metadata of the code execution.\n",
        "            \"\"\"\n",
        "\n",
        "            if reset_session:\n",
        "                if self.process is not None:\n",
        "                    # If a previous process exists, clean it up before starting a new one.\n",
        "                    self.cleanup_session()\n",
        "                self.create_process()  # Create a new child process.\n",
        "            else:\n",
        "                # For the first execution, reset_session must be True.\n",
        "                assert self.process is not None\n",
        "\n",
        "            assert self.process.is_alive()  # Ensure that the child process is running.\n",
        "\n",
        "            self.code_inq.put(code)  # Send the code to the child process via the queue.\n",
        "\n",
        "            # Wait for the child process to signal that it is ready.\n",
        "            try:\n",
        "                state = self.event_outq.get(timeout=10)  # Wait up to 10 seconds for the \"state:ready\" event.\n",
        "            except queue.Empty:\n",
        "                msg = \"REPL child process failed to start execution\"\n",
        "                print(\"critical: \",msg)  # Log a critical error if the process does not start.\n",
        "                while not self.result_outq.empty():\n",
        "                    continue  # Drain the result queue.\n",
        "                raise RuntimeError(msg) from None\n",
        "            assert state[0] == \"state:ready\", state  # Verify that the received state is \"state:ready\".\n",
        "            start_time = time.time()  # Record the start time of execution.\n",
        "\n",
        "            child_in_overtime = False  # Flag to indicate if the child process has exceeded the timeout.\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    # Try to get the finished state from the child process.\n",
        "                    state = self.event_outq.get(timeout=1)  # Wait for the \"state:finished\" event.\n",
        "                    assert state[0] == \"state:finished\", state  # Ensure the state is \"state:finished\".\n",
        "                    exec_time = time.time() - start_time  # Calculate the total execution time.\n",
        "                    break  # Exit the loop if execution is finished.\n",
        "                except queue.Empty:\n",
        "                    # If no event is received, check whether the process is still alive.\n",
        "                    if not child_in_overtime and not self.process.is_alive():\n",
        "                        msg = \"REPL child process died unexpectedly\"\n",
        "                        raise RuntimeError(msg) from None\n",
        "\n",
        "                    # If the process is still running, check if it has exceeded the timeout.\n",
        "                    if self.timeout is None:\n",
        "                        continue\n",
        "                    running_time = time.time() - start_time  # Determine the running time.\n",
        "                    if running_time > self.timeout:\n",
        "                        print(f\"Execution exceeded timeout of {self.timeout}s\")  # Log a timeout message.\n",
        "                        os.kill(self.process.pid, signal.SIGINT)  # Send SIGINT to the process.\n",
        "                        child_in_overtime = True  # Mark that the process is now in overtime.\n",
        "\n",
        "                        # If the process exceeds the timeout by more than 5 seconds, force cleanup.\n",
        "                        if running_time > self.timeout + 5:\n",
        "                            self.cleanup_session()  # Clean up the child process.\n",
        "\n",
        "                            state = (None, \"TimeoutError\", {}, [])  # Set state to indicate a timeout error.\n",
        "                            exec_time = self.timeout  # Set the execution time to the timeout limit.\n",
        "                            break\n",
        "\n",
        "            output: list[str] = []  # Initialize a list to collect output lines.\n",
        "            # Collect all output from the result queue until the EOF marker is encountered.\n",
        "            start_collect = time.time()  # Record the start time for output collection.\n",
        "            while not self.result_outq.empty() or not output or output[-1] != \"<|EOF|>\":\n",
        "                try:\n",
        "                    # If output collection exceeds 5 seconds, log a warning.\n",
        "                    if time.time() - start_collect > 5:\n",
        "                        print(\"Output collection timed out\")\n",
        "                        break\n",
        "                    output.append(self.result_outq.get(timeout=1))  # Append the next line of output.\n",
        "                except queue.Empty:\n",
        "                    continue  # Continue if no output is available immediately.\n",
        "            output.pop()  # Remove the EOF marker from the output list.\n",
        "\n",
        "            # Extract exception information from the finished state.\n",
        "            e_cls_name, exc_info, exc_stack = state[1:]\n",
        "\n",
        "            if e_cls_name == \"TimeoutError\":\n",
        "                # Append a timeout error message to the output if a timeout occurred.\n",
        "                output.append(\n",
        "                    f\"TimeoutError: Execution exceeded the time limit of {humanize.naturaldelta(self.timeout)}\"\n",
        "                )\n",
        "            else:\n",
        "                # Append the execution time information to the output.\n",
        "                output.append(\n",
        "                    f\"Execution time: {humanize.naturaldelta(exec_time)} seconds (time limit is {humanize.naturaldelta(self.timeout)}).\"\n",
        "                )\n",
        "            # Return an ExecutionResult object with all the execution details.\n",
        "            return ExecutionResult(output, exec_time, e_cls_name, exc_info, exc_stack)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJy6O6WpnQCM"
      },
      "source": [
        "### Nodes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ef9JvWJr7Xvg"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import time\n",
        "    import uuid\n",
        "    from dataclasses import dataclass, field\n",
        "    from typing import Literal, Optional\n",
        "\n",
        "    from dataclasses_json import DataClassJsonMixin\n",
        "\n",
        "\n",
        "    @dataclass(eq=False)\n",
        "    class Node(DataClassJsonMixin):\n",
        "        \"\"\"A single node in the solution tree. Contains code, execution results, and evaluation information.\"\"\"\n",
        "\n",
        "        # ---- code & plan ----\n",
        "        code: str\n",
        "        plan: str = field(default=None, kw_only=True)  # type: ignore\n",
        "\n",
        "        # ---- general attrs ----\n",
        "        step: int = field(default=None, kw_only=True)  # type: ignore\n",
        "        id: str = field(default_factory=lambda: uuid.uuid4().hex, kw_only=True)\n",
        "        ctime: float = field(default_factory=lambda: time.time(), kw_only=True)\n",
        "        parent: Optional[\"Node\"] = field(default=None, kw_only=True)\n",
        "        children: set[\"Node\"] = field(default_factory=set, kw_only=True)\n",
        "\n",
        "        # ---- execution info ----\n",
        "        _term_out: list[str] = field(default=None, kw_only=True)  # type: ignore\n",
        "        exec_time: float = field(default=None, kw_only=True)  # type: ignore\n",
        "        exc_type: str | None = field(default=None, kw_only=True)\n",
        "        exc_info: dict | None = field(default=None, kw_only=True)\n",
        "        exc_stack: list[tuple] | None = field(default=None, kw_only=True)\n",
        "\n",
        "        # ---- evaluation ----\n",
        "        # post-execution result analysis (findings/feedback)\n",
        "        analysis: str = field(default=None, kw_only=True)  # type: ignore\n",
        "        metric: float = field(default=None, kw_only=True)  # type: ignore\n",
        "        # whether the agent decided that the code is buggy\n",
        "        # -> always True if exc_type is not None or no valid metric\n",
        "        is_buggy: bool = field(default=None, kw_only=True)  # type: ignore\n",
        "\n",
        "        def __post_init__(self) -> None:\n",
        "            if self.parent is not None:\n",
        "                self.parent.children.add(self)\n",
        "\n",
        "        @property\n",
        "        def stage_name(self) -> Literal[\"draft\", \"debug\", \"improve\"]:\n",
        "            \"\"\"\n",
        "            Return the stage of the node:\n",
        "            - \"stage\" if the node is an initial solution draft\n",
        "            - \"debug\" if the node is the result of a debugging step\n",
        "            - \"improve\" if the node is the result of an improvement step\n",
        "            \"\"\"\n",
        "            if self.parent is None:\n",
        "                return \"draft\"\n",
        "            return \"debug\" if self.parent.is_buggy else \"improve\"\n",
        "\n",
        "        def absorb_exec_result(self, exec_result: ExecutionResult):\n",
        "            \"\"\"Absorb the result of executing the code from this node.\"\"\"\n",
        "            self._term_out = exec_result.term_out\n",
        "            self.exec_time = exec_result.exec_time\n",
        "            self.exc_type = exec_result.exc_type\n",
        "            self.exc_info = exec_result.exc_info\n",
        "            self.exc_stack = exec_result.exc_stack\n",
        "\n",
        "        @property\n",
        "        def term_out(self) -> str:\n",
        "            \"\"\"Get the terminal output of the code execution (after truncating it).\"\"\"\n",
        "            return trim_long_string(\"\".join(self._term_out))\n",
        "\n",
        "        @property\n",
        "        def is_leaf(self) -> bool:\n",
        "            \"\"\"Check if the node is a leaf node in the solution tree.\"\"\"\n",
        "            return not self.children\n",
        "\n",
        "        def __eq__(self, other):\n",
        "            return isinstance(other, Node) and self.id == other.id\n",
        "\n",
        "        def __hash__(self):\n",
        "            return hash(self.id)\n",
        "\n",
        "        @property\n",
        "        def debug_depth(self) -> int:\n",
        "            \"\"\"\n",
        "            Length of the current debug path\n",
        "            - 0 if the node is not a debug node (parent is not buggy)\n",
        "            - 1 if the parent is buggy but the skip parent isn't\n",
        "            - n if there were n consecutive debugging steps\n",
        "            \"\"\"\n",
        "            if self.stage_name != \"debug\":\n",
        "                return 0\n",
        "            return self.parent.debug_depth + 1  # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr5hZPyKnO8y"
      },
      "source": [
        "### Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hdIKQ-ZHnQmY"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Journal(DataClassJsonMixin):\n",
        "    \"\"\"A collection of nodes representing the solution tree.\"\"\"\n",
        "\n",
        "    nodes: list[Node] = field(default_factory=list)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Node:\n",
        "        return self.nodes[idx]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Return the number of nodes in the journal.\"\"\"\n",
        "        return len(self.nodes)\n",
        "\n",
        "    def append(self, node: Node) -> None:\n",
        "        \"\"\"Append a new node to the journal.\"\"\"\n",
        "        node.step = len(self.nodes)\n",
        "        self.nodes.append(node)\n",
        "\n",
        "    @property\n",
        "    def draft_nodes(self) -> list[Node]:\n",
        "        \"\"\"Return a list of nodes representing intial coding drafts\"\"\"\n",
        "        return [n for n in self.nodes if n.parent is None]\n",
        "\n",
        "    @property\n",
        "    def buggy_nodes(self) -> list[Node]:\n",
        "        \"\"\"Return a list of nodes that are considered buggy by the agent.\"\"\"\n",
        "        return [n for n in self.nodes if n.is_buggy]\n",
        "\n",
        "    @property\n",
        "    def good_nodes(self) -> list[Node]:\n",
        "        \"\"\"Return a list of nodes that are not considered buggy by the agent.\"\"\"\n",
        "        return [n for n in self.nodes if not n.is_buggy]\n",
        "\n",
        "    def get_metric_history(self) -> list[float]:\n",
        "        \"\"\"Return a list of all metric values in the journal.\"\"\"\n",
        "        return [n.metric for n in self.nodes]\n",
        "\n",
        "    def get_good_nodes(self) -> Node:\n",
        "        return [n for n in self.nodes if not n.is_buggy]\n",
        "\n",
        "    def get_best_node(self, only_good=True) -> None | Node:\n",
        "        \"\"\"Return the best solution found so far (node with the highest validation metric).\"\"\"\n",
        "        if only_good:\n",
        "            nodes = self.good_nodes\n",
        "            if not nodes:\n",
        "                return None\n",
        "        else:\n",
        "            nodes = self.nodes\n",
        "        return min(nodes, key=lambda n: n.metric)\n",
        "\n",
        "    def generate_summary(self, include_code: bool = False) -> str:\n",
        "        \"\"\"Generate a summary of the journal for the agent.\"\"\"\n",
        "        summary = []\n",
        "        for n in self.good_nodes:\n",
        "            summary_part = f\"Design: {n.plan}\\n\"\n",
        "            if include_code:\n",
        "                summary_part += f\"Code: {n.code}\\n\"\n",
        "            summary_part += f\"Results: {n.analysis}\\n\"\n",
        "            summary_part += f\"Validation Metric (Mean Squared Error): {n.metric}\\n\"\n",
        "            summary.append(summary_part)\n",
        "        return \"\\n-------------------------------\\n\".join(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHofZDRkfCBg"
      },
      "source": [
        "### Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5Sg4cBTy7JIO"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import random\n",
        "    from typing import Any, Callable, cast\n",
        "\n",
        "    import re\n",
        "    import sys\n",
        "    import json\n",
        "    import humanize\n",
        "\n",
        "    from pydantic import BaseModel\n",
        "\n",
        "    ExecCallbackType = Callable[[str, bool], ExecutionResult]\n",
        "\n",
        "\n",
        "    class Agent:\n",
        "        def __init__(\n",
        "            self,\n",
        "            cfg,\n",
        "            journal: Journal,\n",
        "        ):\n",
        "            super().__init__()\n",
        "            self.cfg = cfg\n",
        "            self.journal = journal\n",
        "            self.data_preview: str | None = None\n",
        "\n",
        "        def search_policy(self) -> Node | None:\n",
        "            \"\"\"Select a node to work on (or None to draft a new node).\"\"\"\n",
        "            search_cfg = self.cfg.agent.search\n",
        "\n",
        "            # initial drafting\n",
        "            if len(self.journal.draft_nodes) < search_cfg.num_drafts:\n",
        "                return None\n",
        "\n",
        "            # debugging\n",
        "            if random.random() < search_cfg.debug_prob:\n",
        "                # nodes that are buggy + leaf nodes + debug depth < max debug depth\n",
        "                debuggable_nodes = [\n",
        "                    n\n",
        "                    for n in self.journal.buggy_nodes\n",
        "                    if n.is_leaf\n",
        "                ]\n",
        "                if debuggable_nodes:\n",
        "                    return random.choice(debuggable_nodes)\n",
        "\n",
        "\n",
        "            # back to drafting if no nodes to improve\n",
        "            good_nodes = self.journal.good_nodes\n",
        "            if not good_nodes:\n",
        "                return None\n",
        "\n",
        "            # greedy\n",
        "            greedy_node = self.journal.get_best_node()\n",
        "\n",
        "            return greedy_node\n",
        "\n",
        "\n",
        "        def plan_and_code_query(self, system_message, user_message, retries=3) -> tuple[str, str]:\n",
        "            \"\"\"Generate a natural language plan + code in the same LLM call and split them apart.\"\"\"\n",
        "            completion_text = None\n",
        "            for _ in range(retries):\n",
        "\n",
        "                response = generate_response(\n",
        "                    myModel,\n",
        "                    _messages=[\n",
        "                        {'role': 'system', \"content\": system_message},\n",
        "                        {'role': 'user', \"content\": user_message}\n",
        "                    ]\n",
        "                )\n",
        "                completion_text = response\n",
        "                code = extract_code(completion_text)\n",
        "                nl_text = extract_text_up_to_code(completion_text)\n",
        "\n",
        "                if code:\n",
        "                    return nl_text, code\n",
        "\n",
        "                print(\"Plan + code extraction failed, retrying...\")\n",
        "            print(\"Final plan + code extraction attempt failed, giving up...\")\n",
        "            return \"\", completion_text\n",
        "\n",
        "        def _draft(self) -> Node:\n",
        "\n",
        "            # ================ TODO: ask LLM agents to come up with a solution and then implement ================\n",
        "\n",
        "            system_prompt = \"You are an AI agent.\"\n",
        "\n",
        "            user_prompt = [\n",
        "                \"You have to come up with a solution for machine learning task and then implement this solution in Python.\"\n",
        "                f\"The task is to {str(self.cfg.task_goal)} \",\n",
        "                f'All the provided input data is stored in \"{self.cfg.data_dir}\" directory.',\n",
        "                f\"{str(self.data_preview)}\",\n",
        "                'You have to save the predictions result on testing set in \"/content/submission.csv\".',\n",
        "                'Note that the testing file DOES NOT have the target column.'\n",
        "            ]\n",
        "\n",
        "            system_message = system_prompt\n",
        "            user_message = \"\\n\".join(user_prompt)\n",
        "            plan, code = self.plan_and_code_query(system_message=system_message, user_message=user_message)\n",
        "            return Node(plan=plan, code=code)\n",
        "\n",
        "        def _improve(self, parent_node: Node) -> Node:\n",
        "\n",
        "            # ================  TODO: ask LLM agent to improve drafts ================\n",
        "\n",
        "            system_prompt = \"You are an AI assistant.\"\n",
        "\n",
        "            user_prompt = [\n",
        "                f\"Task description: {str(self.cfg.task_goal)} \"\n",
        "                f\"Memory: {str(self.journal.generate_summary())} \"\n",
        "                f\"Previous solution: Code: {str(wrap_code(parent_node.code))} \"\n",
        "            ]\n",
        "            system_message = system_prompt\n",
        "            user_message = \" \".join(user_prompt)\n",
        "            plan, code = self.plan_and_code_query(system_message=system_message, user_message=user_message)\n",
        "            return Node(plan=plan, code=code, parent=parent_node)\n",
        "\n",
        "        def _debug(self, parent_node: Node) -> Node:\n",
        "\n",
        "            # ================  TODO: ask LLM agent to debug ================\n",
        "            system_prompt = \"You are an AI agent.\"\n",
        "\n",
        "\n",
        "            user_prompt = [\n",
        "                f\"Task description: {str(self.cfg.task_goal)}\\n\\n\",\n",
        "                f\"Previous (buggy) implementation: {str(wrap_code(parent_node.code))}\\n\\n\",\n",
        "                f\"Execution output: {str(wrap_code(parent_node.term_out, lang=''))}\\n\\n\",\n",
        "                str(self.data_preview)\n",
        "            ]\n",
        "\n",
        "            system_message = system_prompt\n",
        "            user_message = \" \".join(user_prompt)\n",
        "\n",
        "            plan, code = self.plan_and_code_query(system_message=system_message, user_message=user_message)\n",
        "            return Node(plan=plan, code=code, parent=parent_node)\n",
        "\n",
        "        def update_data_preview(\n",
        "            self,\n",
        "        ):\n",
        "            self.data_preview = data_preview_generate(cfg.data_dir)\n",
        "\n",
        "        def step(self, exec_callback: ExecCallbackType):\n",
        "            if not self.journal.nodes or self.data_preview is None:\n",
        "                self.update_data_preview()\n",
        "\n",
        "            parent_node = self.search_policy()\n",
        "\n",
        "            if parent_node is None:\n",
        "                result_node = self._draft()\n",
        "            elif parent_node.is_buggy:\n",
        "                result_node = self._debug(parent_node)\n",
        "            else:\n",
        "                result_node = self._improve(parent_node)\n",
        "\n",
        "            self.parse_exec_result(\n",
        "                node=result_node,\n",
        "                exec_result=exec_callback(result_node.code, True),\n",
        "            )\n",
        "            self.journal.append(result_node)\n",
        "\n",
        "        def parse_exec_result(self, node: Node, exec_result: ExecutionResult):\n",
        "            node.absorb_exec_result(exec_result)\n",
        "\n",
        "            system_prompt = \"You are an AI assistant.\"\n",
        "\n",
        "            # ================  TODO: ask LLM agent to extract evaluation result from the execution output. ================\n",
        "            # save log file\n",
        "            user_prompt = f\"\"\"\n",
        "                The task is:\n",
        "                {self.cfg.task_goal}\n",
        "\n",
        "                The code implementation is:\n",
        "                {wrap_code(node.code)}\n",
        "\n",
        "                The execution output is:\n",
        "                {wrap_code(node.term_out, lang=\"\")}\n",
        "            \"\"\"\n",
        "\n",
        "            system_message = system_prompt\n",
        "            user_message = \" \".join(user_prompt)\n",
        "\n",
        "            response = generate_response(\n",
        "                myModel,\n",
        "                _messages=[\n",
        "                    {'role': 'system', \"content\": system_message},\n",
        "                    {'role': 'user', \"content\": user_message}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            # ================  TODO: evaluation ================\n",
        "            # you can force the LLM to structure the output to extract the metric\n",
        "            # reference: https://python.useinstructor.com/integrations/llama-cpp-python/#llama-cpp-python\n",
        "            # node.analysis = response.summary\n",
        "            # node.is_buggy = (\n",
        "            #     response.is_buggy\n",
        "            #     or node.exc_type is not None\n",
        "            #     or response.metric is None\n",
        "            # )\n",
        "\n",
        "            node.is_buggy = False\n",
        "            node.metric = 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di-9OGwOiZgl"
      },
      "source": [
        "### Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "S1csIXAO6i8i"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import json\n",
        "    import re\n",
        "\n",
        "    def wrap_code(code: str, lang=\"python\") -> str:\n",
        "        \"\"\"Wraps code with three backticks.\"\"\"\n",
        "        return f\"```{lang}\\n{code}\\n```\"\n",
        "\n",
        "\n",
        "    def is_valid_python_script(script):\n",
        "        \"\"\"Check if a script is a valid Python script.\"\"\"\n",
        "        try:\n",
        "            compile(script, \"<string>\", \"exec\")\n",
        "            return True\n",
        "        except SyntaxError:\n",
        "            return False\n",
        "\n",
        "\n",
        "    def extract_jsons(text):\n",
        "        \"\"\"Extract all JSON objects from the text. Caveat: This function cannot handle nested JSON objects.\"\"\"\n",
        "        json_objects = []\n",
        "\n",
        "        # Find {} by regular expression\n",
        "        matches = re.findall(r\"\\{.*?\\}\", text, re.DOTALL)\n",
        "\n",
        "        # Try to transform string into json objects\n",
        "        for match in matches:\n",
        "            try:\n",
        "                json_obj = json.loads(match)\n",
        "                json_objects.append(json_obj)\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "\n",
        "        return json_objects\n",
        "\n",
        "    def trim_long_string(string, threshold=5100, k=2500):\n",
        "        # Check if the length of the string is longer than the threshold\n",
        "        if len(string) > threshold:\n",
        "            # Output the first k and last k characters\n",
        "            first_k_chars = string[:k]\n",
        "            last_k_chars = string[-k:]\n",
        "\n",
        "            truncated_len = len(string) - 2 * k\n",
        "\n",
        "            return f\"{first_k_chars}\\n ... [{truncated_len} characters truncated] ... \\n{last_k_chars}\"\n",
        "        else:\n",
        "            return string\n",
        "\n",
        "    def extract_code(text):\n",
        "        \"\"\"Extract python code blocks from the text.\"\"\"\n",
        "        parsed_codes = []\n",
        "\n",
        "        # When code is in a text or python block\n",
        "        matches = re.findall(r\"```(python)?\\n*(.*?)\\n*```\", text, re.DOTALL)\n",
        "        for match in matches:\n",
        "            code_block = match[1]\n",
        "            parsed_codes.append(code_block)\n",
        "\n",
        "        # When the entire text is code or backticks of the code block is missing\n",
        "        if len(parsed_codes) == 0:\n",
        "            matches = re.findall(r\"^(```(python)?)?\\n?(.*?)\\n?(```)?$\", text, re.DOTALL)\n",
        "            if matches:\n",
        "                code_block = matches[0][2]\n",
        "                parsed_codes.append(code_block)\n",
        "\n",
        "        # validate the parsed codes\n",
        "        valid_code_blocks = [\n",
        "            c for c in parsed_codes if is_valid_python_script(c)\n",
        "        ]\n",
        "        return \"\\n\\n\".join(valid_code_blocks)\n",
        "\n",
        "    def extract_text_up_to_code(s):\n",
        "        \"\"\"Extract (presumed) natural language text up to the start of the first code block.\"\"\"\n",
        "        if \"```\" not in s:\n",
        "            return \"\"\n",
        "        return s[: s.find(\"```\")].strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26WSVJyCnC1j"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f8hRG2o7yeoc"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import json\n",
        "    from pathlib import Path\n",
        "\n",
        "    import humanize\n",
        "    import pandas as pd\n",
        "\n",
        "\n",
        "    def preview_csv(p: Path) -> str:\n",
        "        \"\"\"Generate a textual preview of a csv file\"\"\"\n",
        "\n",
        "        df = pd.read_csv(p)\n",
        "\n",
        "        out = []\n",
        "\n",
        "        out.append(f\"-> {str(p)} has {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
        "\n",
        "        # ================  TODO: Tell LLM agents which feature is useful for prediction ================\n",
        "\n",
        "        cols = df.columns.tolist()\n",
        "        cols_str = \", \".join(cols)\n",
        "        res = f\"The columns are: {cols_str}\"\n",
        "\n",
        "        out.append(res)\n",
        "\n",
        "        return \"\\n\".join(out)\n",
        "\n",
        "    def data_preview_generate(base_path):\n",
        "        \"\"\"\n",
        "        Generate a textual preview of a directory\n",
        "        \"\"\"\n",
        "\n",
        "        result = []\n",
        "        files = [p for p in Path(base_path).iterdir()]\n",
        "        for f in sorted(files):\n",
        "            result.append(preview_csv(f))\n",
        "\n",
        "        result = \"\\n\\n\".join(result)\n",
        "\n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qeTrqDrbVtZ"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-yeyuK6n6tY5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# DO NOT MODIFY THIS CELL\n",
        "class Config:\n",
        "    \"\"\"\n",
        "    A recursive configuration class that converts a dictionary into an object\n",
        "    with attributes accessible using dot notation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dictionary):\n",
        "        for key, value in dictionary.items():\n",
        "            if isinstance(value, dict):\n",
        "                value = Config(value)\n",
        "            setattr(self, key, value)\n",
        "\n",
        "def set_seed(seed=531):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6rGMZ96i6LwT"
      },
      "outputs": [],
      "source": [
        "# ================  TODO: config ================\n",
        "config = {\n",
        "    # experiment configurations\n",
        "    \"exp_name\": \"ML2025_HW2\",\n",
        "    # \"data_dir\":  Path(\"/content/ML2025Spring-hw2-public\").resolve(),\n",
        "    \"data_dir\":  Path(\"./data\").resolve(),\n",
        "\n",
        "    # the description of the task\n",
        "    \"task_goal\": \"Given the survey results from the past two days in a specific state in the U.S.,\\\n",
        "                  predict the probability of testing positive on day 3. \\\n",
        "                  The evaluation metric is Mean Squared Error (MSE).\",\n",
        "\n",
        "    \"agent\": {\n",
        "        # the number of iterations\n",
        "        \"steps\": 1,\n",
        "        \"search\": {\n",
        "            # decide whether to debug or improve\n",
        "            \"debug_prob\": 0.5,\n",
        "            # the number of draft generated before improving/debugging\n",
        "            \"num_drafts\": 1,\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "cfg = Config(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_DTmIU8_Pkz"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YHG21H719_A3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "critical:  REPL child process failed to start execution\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "REPL child process failed to start execution",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     26\u001b[39m     interpreter.cleanup_session()\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     15\u001b[39m global_step = \u001b[38;5;28mlen\u001b[39m(journal)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m global_step < cfg.agent.steps:\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# run agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# save results for this iteration\u001b[39;00m\n\u001b[32m     20\u001b[39m     save_run(cfg, journal)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 155\u001b[39m, in \u001b[36mAgent.step\u001b[39m\u001b[34m(self, exec_callback)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    151\u001b[39m     result_node = \u001b[38;5;28mself\u001b[39m._improve(parent_node)\n\u001b[32m    153\u001b[39m \u001b[38;5;28mself\u001b[39m.parse_exec_result(\n\u001b[32m    154\u001b[39m     node=result_node,\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     exec_result=\u001b[43mexec_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_node\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[32m    156\u001b[39m )\n\u001b[32m    157\u001b[39m \u001b[38;5;28mself\u001b[39m.journal.append(result_node)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mmain.<locals>.exec_callback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexec_callback\u001b[39m(*args, **kwargs):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     res = \u001b[43minterpreter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 212\u001b[39m, in \u001b[36mInterpreter.run\u001b[39m\u001b[34m(self, code, reset_session)\u001b[39m\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.result_outq.empty():\n\u001b[32m    211\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Drain the result queue.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m state[\u001b[32m0\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mstate:ready\u001b[39m\u001b[33m\"\u001b[39m, state  \u001b[38;5;66;03m# Verify that the received state is \"state:ready\".\u001b[39;00m\n\u001b[32m    214\u001b[39m start_time = time.time()  \u001b[38;5;66;03m# Record the start time of execution.\u001b[39;00m\n",
            "\u001b[31mRuntimeError\u001b[39m: REPL child process failed to start execution"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "\n",
        "    def exec_callback(*args, **kwargs):\n",
        "        res = interpreter.run(*args, **kwargs)\n",
        "        return res\n",
        "\n",
        "    journal = Journal()\n",
        "    agent = Agent(\n",
        "        cfg=cfg,\n",
        "        journal=journal,\n",
        "    )\n",
        "\n",
        "    interpreter = Interpreter()\n",
        "\n",
        "    global_step = len(journal)\n",
        "    while global_step < cfg.agent.steps:\n",
        "        # run agent\n",
        "        agent.step(exec_callback=exec_callback)\n",
        "        # save results for this iteration\n",
        "        save_run(cfg, journal)\n",
        "        # get currect step\n",
        "        global_step = len(journal)\n",
        "\n",
        "\n",
        "    # Kill created child process\n",
        "    interpreter.cleanup_session()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD5bPjF5dO2Y"
      },
      "outputs": [],
      "source": [
        "# Get your best result!\n",
        "# !python best_solution.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feFaoy8tbvyC"
      },
      "source": [
        "# References\n",
        "The code scripts are from [aideml](https://github.com/WecoAI/aideml) project on github with some modifications.\n",
        "\n",
        "AIDE: AI-Driven Exploration in the Space of Code\n",
        "https://arxiv.org/pdf/2502.13138\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Jf1drXU_MvAP"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ML2025",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
